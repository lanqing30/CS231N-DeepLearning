{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "\n",
    "def extract_features(imgs, feature_fns, verbose=False):\n",
    "  \"\"\"\n",
    "  Given pixel data for images and several feature functions that can operate on\n",
    "  single images, apply all feature functions to all images, concatenating the\n",
    "  feature vectors for each image and storing the features for all images in\n",
    "  a single matrix.\n",
    "\n",
    "  Inputs:\n",
    "  - imgs: N x H X W X C array of pixel data for N images.\n",
    "  - feature_fns: List of k feature functions. The ith feature function should\n",
    "    take as input an H x W x D array and return a (one-dimensional) array of\n",
    "    length F_i.\n",
    "  - verbose: Boolean; if true, print progress.\n",
    "\n",
    "  Returns:\n",
    "  An array of shape (N, F_1 + ... + F_k) where each column is the concatenation\n",
    "  of all features for a single image.\n",
    "  \"\"\"\n",
    "  num_images = imgs.shape[0]\n",
    "  if num_images == 0:\n",
    "    return np.array([])\n",
    "\n",
    "  # Use the first image to determine feature dimensions\n",
    "  feature_dims = []\n",
    "  first_image_features = []\n",
    "  for feature_fn in feature_fns:\n",
    "    feats = feature_fn(imgs[0].squeeze())\n",
    "    assert len(feats.shape) == 1, 'Feature functions must be one-dimensional'\n",
    "    feature_dims.append(feats.size)\n",
    "    first_image_features.append(feats)\n",
    "\n",
    "  # Now that we know the dimensions of the features, we can allocate a single\n",
    "  # big array to store all features as columns.\n",
    "  total_feature_dim = sum(feature_dims)\n",
    "  imgs_features = np.zeros((num_images, total_feature_dim))\n",
    "  imgs_features[0] = np.hstack(first_image_features).T\n",
    "\n",
    "  # Extract features for the rest of the images.\n",
    "  for i in range(1, num_images):\n",
    "    idx = 0\n",
    "    for feature_fn, feature_dim in zip(feature_fns, feature_dims):\n",
    "      next_idx = idx + feature_dim\n",
    "      imgs_features[i, idx:next_idx] = feature_fn(imgs[i].squeeze())\n",
    "      idx = next_idx\n",
    "    if verbose and i % 1000 == 0:\n",
    "      print('Done extracting features for %d / %d images' % (i, num_images))\n",
    "\n",
    "  return imgs_features\n",
    "\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "  \"\"\"Convert RGB image to grayscale\n",
    "\n",
    "    Parameters:\n",
    "      rgb : RGB image\n",
    "\n",
    "    Returns:\n",
    "      gray : grayscale image\n",
    "  \n",
    "  \"\"\"\n",
    "  return np.dot(rgb[...,:3], [0.299, 0.587, 0.144])\n",
    "\n",
    "\n",
    "def hog_feature(im):\n",
    "  \"\"\"Compute Histogram of Gradient (HOG) feature for an image\n",
    "  \n",
    "       Modified from skimage.feature.hog\n",
    "       http://pydoc.net/Python/scikits-image/0.4.2/skimage.feature.hog\n",
    "     \n",
    "     Reference:\n",
    "       Histograms of Oriented Gradients for Human Detection\n",
    "       Navneet Dalal and Bill Triggs, CVPR 2005\n",
    "     \n",
    "    Parameters:\n",
    "      im : an input grayscale or rgb image\n",
    "      \n",
    "    Returns:\n",
    "      feat: Histogram of Gradient (HOG) feature\n",
    "    \n",
    "  \"\"\"\n",
    "  \n",
    "  # convert rgb to grayscale if needed\n",
    "  if im.ndim == 3:\n",
    "    image = rgb2gray(im)\n",
    "  else:\n",
    "    image = np.at_least_2d(im)\n",
    "\n",
    "  sx, sy = image.shape # image size\n",
    "  orientations = 9 # number of gradient bins\n",
    "  cx, cy = (8, 8) # pixels per cell\n",
    "\n",
    "  gx = np.zeros(image.shape)\n",
    "  gy = np.zeros(image.shape)\n",
    "  gx[:, :-1] = np.diff(image, n=1, axis=1) # compute gradient on x-direction\n",
    "  gy[:-1, :] = np.diff(image, n=1, axis=0) # compute gradient on y-direction\n",
    "  grad_mag = np.sqrt(gx ** 2 + gy ** 2) # gradient magnitude\n",
    "  grad_ori = np.arctan2(gy, (gx + 1e-15)) * (180 / np.pi) + 90 # gradient orientation\n",
    "\n",
    "  n_cellsx = int(np.floor(sx / cx))  # number of cells in x\n",
    "  n_cellsy = int(np.floor(sy / cy))  # number of cells in y\n",
    "  # compute orientations integral images\n",
    "  orientation_histogram = np.zeros((n_cellsx, n_cellsy, orientations))\n",
    "  for i in range(orientations):\n",
    "    # create new integral image for this orientation\n",
    "    # isolate orientations in this range\n",
    "    temp_ori = np.where(grad_ori < 180 / orientations * (i + 1),\n",
    "                        grad_ori, 0)\n",
    "    temp_ori = np.where(grad_ori >= 180 / orientations * i,\n",
    "                        temp_ori, 0)\n",
    "    # select magnitudes for those orientations\n",
    "    cond2 = temp_ori > 0\n",
    "    temp_mag = np.where(cond2, grad_mag, 0)\n",
    "    orientation_histogram[:,:,i] = uniform_filter(temp_mag, size=(cx, cy))[int(cx/2)::cx, int(cy/2)::cy].T\n",
    "  \n",
    "  return orientation_histogram.ravel()\n",
    "\n",
    "\n",
    "def color_histogram_hsv(im, nbin=10, xmin=0, xmax=255, normalized=True):\n",
    "  \"\"\"\n",
    "  Compute color histogram for an image using hue.\n",
    "\n",
    "  Inputs:\n",
    "  - im: H x W x C array of pixel data for an RGB image.\n",
    "  - nbin: Number of histogram bins. (default: 10)\n",
    "  - xmin: Minimum pixel value (default: 0)\n",
    "  - xmax: Maximum pixel value (default: 255)\n",
    "  - normalized: Whether to normalize the histogram (default: True)\n",
    "\n",
    "  Returns:\n",
    "    1D vector of length nbin giving the color histogram over the hue of the\n",
    "    input image.\n",
    "  \"\"\"\n",
    "  ndim = im.ndim\n",
    "  bins = np.linspace(xmin, xmax, nbin+1)\n",
    "  hsv = matplotlib.colors.rgb_to_hsv(im/xmax) * xmax\n",
    "  imhist, bin_edges = np.histogram(hsv[:,:,0], bins=bins, density=normalized)\n",
    "  imhist = imhist * np.diff(bin_edges)\n",
    "\n",
    "  # return histogram\n",
    "  return imhist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import load_CIFAR10\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    # Load the raw CIFAR-10 data\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10('datasets/cifar-10-batches-py')\n",
    "    \n",
    "    # Subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done extracting features for 1000 / 49000 images\n",
      "Done extracting features for 2000 / 49000 images\n",
      "Done extracting features for 3000 / 49000 images\n",
      "Done extracting features for 4000 / 49000 images\n",
      "Done extracting features for 5000 / 49000 images\n",
      "Done extracting features for 6000 / 49000 images\n",
      "Done extracting features for 7000 / 49000 images\n",
      "Done extracting features for 8000 / 49000 images\n",
      "Done extracting features for 9000 / 49000 images\n",
      "Done extracting features for 10000 / 49000 images\n",
      "Done extracting features for 11000 / 49000 images\n",
      "Done extracting features for 12000 / 49000 images\n",
      "Done extracting features for 13000 / 49000 images\n",
      "Done extracting features for 14000 / 49000 images\n",
      "Done extracting features for 15000 / 49000 images\n",
      "Done extracting features for 16000 / 49000 images\n",
      "Done extracting features for 17000 / 49000 images\n",
      "Done extracting features for 18000 / 49000 images\n",
      "Done extracting features for 19000 / 49000 images\n",
      "Done extracting features for 20000 / 49000 images\n",
      "Done extracting features for 21000 / 49000 images\n",
      "Done extracting features for 22000 / 49000 images\n",
      "Done extracting features for 23000 / 49000 images\n",
      "Done extracting features for 24000 / 49000 images\n",
      "Done extracting features for 25000 / 49000 images\n",
      "Done extracting features for 26000 / 49000 images\n",
      "Done extracting features for 27000 / 49000 images\n",
      "Done extracting features for 28000 / 49000 images\n",
      "Done extracting features for 29000 / 49000 images\n",
      "Done extracting features for 30000 / 49000 images\n",
      "Done extracting features for 31000 / 49000 images\n",
      "Done extracting features for 32000 / 49000 images\n",
      "Done extracting features for 33000 / 49000 images\n",
      "Done extracting features for 34000 / 49000 images\n",
      "Done extracting features for 35000 / 49000 images\n",
      "Done extracting features for 36000 / 49000 images\n",
      "Done extracting features for 37000 / 49000 images\n",
      "Done extracting features for 38000 / 49000 images\n",
      "Done extracting features for 39000 / 49000 images\n",
      "Done extracting features for 40000 / 49000 images\n",
      "Done extracting features for 41000 / 49000 images\n",
      "Done extracting features for 42000 / 49000 images\n",
      "Done extracting features for 43000 / 49000 images\n",
      "Done extracting features for 44000 / 49000 images\n",
      "Done extracting features for 45000 / 49000 images\n",
      "Done extracting features for 46000 / 49000 images\n",
      "Done extracting features for 47000 / 49000 images\n",
      "Done extracting features for 48000 / 49000 images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_fns = [hog_feature, lambda img: color_histogram_hsv(img, nbin=10)] # Number of bins in the color histogram\n",
    "X_train_feats = extract_features(X_train, feature_fns, verbose=True)\n",
    "X_val_feats = extract_features(X_val, feature_fns)\n",
    "X_test_feats = extract_features(X_test, feature_fns)\n",
    "\n",
    "# Preprocessing: Subtract the mean feature\n",
    "mean_feat = np.mean(X_train_feats, axis=0, keepdims=True)\n",
    "X_train_feats -= mean_feat\n",
    "X_val_feats -= mean_feat\n",
    "X_test_feats -= mean_feat\n",
    "\n",
    "# Preprocessing: Divide by standard deviation. This ensures that each feature\n",
    "# has roughly the same scale.\n",
    "std_feat = np.std(X_train_feats, axis=0, keepdims=True)\n",
    "X_train_feats /= std_feat\n",
    "X_val_feats /= std_feat\n",
    "X_test_feats /= std_feat\n",
    "\n",
    "# Preprocessing: Add a bias dimension\n",
    "X_train_feats = np.hstack([X_train_feats, np.ones((X_train_feats.shape[0], 1))])\n",
    "X_val_feats = np.hstack([X_val_feats, np.ones((X_val_feats.shape[0], 1))])\n",
    "X_test_feats = np.hstack([X_test_feats, np.ones((X_test_feats.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use these features for trainning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
